{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extração"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Durante a análise exploratória inicial dos arquivos CSV, identificamos uma anomalia na formatação: os arquivos originais possuem aspas duplas (`\"`) envolvendo a linha inteira ou campos de forma inconsistente.\n",
    "\n",
    "Ao utilizar o parser padrão do Pandas, isso causava erros de tokenização e deslocamento de colunas.\n",
    "\n",
    "Para contornar isso, optamos por uma leitura \"bruta\" dos dados:\n",
    "1.  Desativamos a interpretação automática de aspas (`quoting=csv.QUOTE_NONE`).\n",
    "2.  Carregamos o conteúdo integralmente.\n",
    "3.  Removemos as aspas residuais (`\"`) manualmente das bordas (primeira e última coluna) e do cabeçalho via manipulação de string."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:19:04.135094Z",
     "start_time": "2025-12-01T16:19:03.747503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:19:18.909524Z",
     "start_time": "2025-12-01T16:19:04.138904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "caminho_pasta = '../data'\n",
    "arquivos_csv = glob.glob(os.path.join(caminho_pasta, '*.csv'))\n",
    "\n",
    "lista_dataframes = []\n",
    "\n",
    "print(f\"Encontrados {len(arquivos_csv)} arquivos na pasta '{caminho_pasta}'.\")\n",
    "\n",
    "for arquivo in arquivos_csv:\n",
    "    try:\n",
    "        print(f\"Processando: {os.path.basename(arquivo)}...\")\n",
    "        df = pd.read_csv(\n",
    "            arquivo,\n",
    "            sep=',',\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "            engine='python',\n",
    "            on_bad_lines='skip',\n",
    "            encoding='utf-8',\n",
    "            dtype=str\n",
    "        )\n",
    "\n",
    "        col_primeira = df.columns[0]\n",
    "        col_ultima = df.columns[-1]\n",
    "\n",
    "        df[col_primeira] = df[col_primeira].astype(str).str.replace('\"', '')\n",
    "        df[col_ultima] = df[col_ultima].astype(str).str.replace('\"', '')\n",
    "        df.columns = df.columns.str.replace('\"', '')\n",
    "\n",
    "        lista_dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
    "\n",
    "if lista_dataframes:\n",
    "    df_raw = pd.concat(lista_dataframes, ignore_index=True)\n",
    "    print(f\"\\nTotal de linhas e colunas no df unificado: {df_raw.shape}\")\n",
    "else:\n",
    "    print(\"\\nNenhum dataframe foi carregado.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 3 arquivos na pasta '../data'.\n",
      "Processando: func2019_completo.csv...\n",
      "Processando: func2020_completo.csv...\n",
      "Processando: func2021_completo.csv...\n",
      "\n",
      "Total de linhas e colunas no df unificado: (1398332, 34)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformação"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Notamos que as colunas possuem nomes codificados (ex: nsalsenome). Para facilitar a análise exploratória, aplicamos um mapeamento inicial para termos de negócio."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:19:20.024253Z",
     "start_time": "2025-12-01T16:19:18.961800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "map_colunas = {\n",
    "    'csalsematr': 'matricula',\n",
    "    'csalseccpf': 'cpf',\n",
    "    'nsalsenome': 'nome',\n",
    "    'esalsegenero': 'genero',\n",
    "    'esalseinstrucao': 'grau_instrucao',\n",
    "    'dslderadmissao': 'data_admissao',\n",
    "    'dslserdesligamento': 'data_desligamento',\n",
    "    'dsalseaposentadoria': 'data_aposentadoria',\n",
    "    'eslserlotacao': 'lotacao_nome',\n",
    "    'esalseunidade': 'unidade_nome',\n",
    "    'nsalseempr': 'entidade_nome',\n",
    "    'esalseadministracao': 'tipo_administracao',\n",
    "    'nsalsecarg': 'cargo_nome',\n",
    "    'nsalsefunc': 'funcao_nome',\n",
    "    'nsalsecate': 'categoria_nome',\n",
    "    'eselsesituacao': 'situacao_nome',\n",
    "    'aslserjornadamensal': 'jornada_mensal',\n",
    "    'tslserulat': 'data_atualizacao_sistema',\n",
    "    'asalseanoo': 'ano_folha',\n",
    "    'asalsemess': 'mes_folha',\n",
    "    'vsalseprov': 'valor_remuneracao_bruta',\n",
    "    'vsalseremu': 'valor_remuneracao_base',\n",
    "    'vsalsecarg': 'valor_salario_base',\n",
    "    'vsalsefunc': 'valor_funcao_gratificada',\n",
    "    'vsalseoutr': 'valor_outras_remuneracoes',\n",
    "    'vsalseferi': 'valor_ferias',\n",
    "    'vsalsenatl': 'valor_13_salario',\n",
    "    'vsalsedife': 'valor_diferenca_salarial',\n",
    "    'vsalsedrrf': 'valor_irrf',\n",
    "    'vsalsedprv': 'valor_previdencia',\n",
    "    'vsalsedtot': 'valor_descontos_total',\n",
    "    'vsalsedrst': 'valor_desconto_faltas',\n",
    "    'vsalsedxcd': 'valor_descontos_diversos',\n",
    "    'vsalseliqd': 'valor_liquido'\n",
    "}\n",
    "\n",
    "df = df_raw.rename(columns=map_colunas)\n",
    "df = df[list(map_colunas.values())].copy()\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  matricula          cpf                          nome     genero  \\\n",
       "0      4480  ***040714**       EVERALDO PADRE DA SILVA  Masculino   \n",
       "1      4529  ***105614**             JOSE ARTUR SEABRA  Masculino   \n",
       "2    512222  ***507834**       VICTOR FELIX SILVA MELO  Masculino   \n",
       "3    512230  ***256834**  DAIANNA M C MAIA DE OLIVEIRA   Feminino   \n",
       "4    512249  ***026244**     ENILTON RUAN M DOS SANTOS  Masculino   \n",
       "\n",
       "    grau_instrucao data_admissao data_desligamento data_aposentadoria  \\\n",
       "0    Mdio Completo    1991-08-30        2021-11-01                NaN   \n",
       "1    Mdio Completo    1991-09-05        2021-10-01                NaN   \n",
       "2  Mdio Incompleto    2019-01-16        2019-07-31                NaN   \n",
       "3  Mdio Incompleto    2019-02-01        2019-11-30                NaN   \n",
       "4  Mdio Incompleto    2019-02-01        2020-12-31                NaN   \n",
       "\n",
       "  lotacao_nome                         unidade_nome  ...  \\\n",
       "0         CTTU    SETOR DE SERVICOS ADMINISTRATIVOS  ...   \n",
       "1         CTTU    SETOR DE SERVICOS ADMINISTRATIVOS  ...   \n",
       "2         CTTU     SETOR DE PROCESSAMENTO DE MULTAS  ...   \n",
       "3         CTTU  GESTAO DE UNID. DE MOB. SUSTENTAVEL  ...   \n",
       "4         CTTU     SETOR DE PROCESSAMENTO DE MULTAS  ...   \n",
       "\n",
       "  valor_outras_remuneracoes valor_ferias valor_13_salario  \\\n",
       "0                     444.6          0.0              0.0   \n",
       "1                     949.0          0.0              0.0   \n",
       "2                     377.0          0.0              0.0   \n",
       "3                     377.0          0.0              0.0   \n",
       "4                     377.0          0.0              0.0   \n",
       "\n",
       "  valor_diferenca_salarial valor_irrf valor_previdencia valor_descontos_total  \\\n",
       "0                      0.0        0.0             131.5                 131.5   \n",
       "1                      0.0        0.0             183.9                 235.9   \n",
       "2                      0.0        0.0               0.0                   0.0   \n",
       "3                      0.0        0.0               0.0                   0.0   \n",
       "4                      0.0        0.0               0.0                   0.0   \n",
       "\n",
       "  valor_desconto_faltas valor_descontos_diversos valor_liquido  \n",
       "0                   0.0                      0.0        1512.0  \n",
       "1                  52.0                      0.0        1911.9  \n",
       "2                   0.0                      0.0         377.0  \n",
       "3                   0.0                      0.0         377.0  \n",
       "4                   0.0                      0.0         377.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matricula</th>\n",
       "      <th>cpf</th>\n",
       "      <th>nome</th>\n",
       "      <th>genero</th>\n",
       "      <th>grau_instrucao</th>\n",
       "      <th>data_admissao</th>\n",
       "      <th>data_desligamento</th>\n",
       "      <th>data_aposentadoria</th>\n",
       "      <th>lotacao_nome</th>\n",
       "      <th>unidade_nome</th>\n",
       "      <th>...</th>\n",
       "      <th>valor_outras_remuneracoes</th>\n",
       "      <th>valor_ferias</th>\n",
       "      <th>valor_13_salario</th>\n",
       "      <th>valor_diferenca_salarial</th>\n",
       "      <th>valor_irrf</th>\n",
       "      <th>valor_previdencia</th>\n",
       "      <th>valor_descontos_total</th>\n",
       "      <th>valor_desconto_faltas</th>\n",
       "      <th>valor_descontos_diversos</th>\n",
       "      <th>valor_liquido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4480</td>\n",
       "      <td>***040714**</td>\n",
       "      <td>EVERALDO PADRE DA SILVA</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Mdio Completo</td>\n",
       "      <td>1991-08-30</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTTU</td>\n",
       "      <td>SETOR DE SERVICOS ADMINISTRATIVOS</td>\n",
       "      <td>...</td>\n",
       "      <td>444.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.5</td>\n",
       "      <td>131.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4529</td>\n",
       "      <td>***105614**</td>\n",
       "      <td>JOSE ARTUR SEABRA</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Mdio Completo</td>\n",
       "      <td>1991-09-05</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTTU</td>\n",
       "      <td>SETOR DE SERVICOS ADMINISTRATIVOS</td>\n",
       "      <td>...</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.9</td>\n",
       "      <td>235.9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1911.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512222</td>\n",
       "      <td>***507834**</td>\n",
       "      <td>VICTOR FELIX SILVA MELO</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Mdio Incompleto</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTTU</td>\n",
       "      <td>SETOR DE PROCESSAMENTO DE MULTAS</td>\n",
       "      <td>...</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512230</td>\n",
       "      <td>***256834**</td>\n",
       "      <td>DAIANNA M C MAIA DE OLIVEIRA</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Mdio Incompleto</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTTU</td>\n",
       "      <td>GESTAO DE UNID. DE MOB. SUSTENTAVEL</td>\n",
       "      <td>...</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512249</td>\n",
       "      <td>***026244**</td>\n",
       "      <td>ENILTON RUAN M DOS SANTOS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Mdio Incompleto</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTTU</td>\n",
       "      <td>SETOR DE PROCESSAMENTO DE MULTAS</td>\n",
       "      <td>...</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Como os dados foram carregados como strings, precisamos converter o tipo de algumas colunas."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:37.269050Z",
     "start_time": "2025-12-01T16:19:20.182123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df[['ano_folha', 'valor_remuneracao_bruta']].dtypes)\n",
    "\n",
    "cols_data = ['data_admissao', 'data_desligamento', 'data_aposentadoria', 'data_atualizacao_sistema']\n",
    "for col in cols_data:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "\n",
    "df['ano_folha'] = pd.to_numeric(df['ano_folha'], errors='coerce').fillna(0).astype(int)\n",
    "df['mes_folha'] = pd.to_numeric(df['mes_folha'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "cols_financeiras = [c for c in df.columns if 'valor_' in c or 'jornada' in c]\n",
    "for col in cols_financeiras:\n",
    "    df[col] = df[col].astype(str).str.replace(',', '.').apply(pd.to_numeric, errors='coerce').fillna(0.0)\n",
    "\n",
    "print(\"\\nTipos corrigidos:\")\n",
    "print(df[['ano_folha', 'valor_remuneracao_bruta']].dtypes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ano_folha                  object\n",
      "valor_remuneracao_bruta    object\n",
      "dtype: object\n",
      "\n",
      "Tipos corrigidos:\n",
      "ano_folha                    int64\n",
      "valor_remuneracao_bruta    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Identificamos valores nulos em colunas críticas. No caso de genero e grau_instrucao, optamos por criar uma categoria 'NI' (Não Informado) para não perder registros."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:37.799314Z",
     "start_time": "2025-12-01T16:20:37.362195Z"
    }
   },
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matricula                          0\n",
       "cpf                                0\n",
       "nome                               0\n",
       "genero                             2\n",
       "grau_instrucao                  4275\n",
       "data_admissao                     36\n",
       "data_desligamento            1113112\n",
       "data_aposentadoria           1053502\n",
       "lotacao_nome                       0\n",
       "unidade_nome                     441\n",
       "entidade_nome                      0\n",
       "tipo_administracao                 0\n",
       "cargo_nome                         0\n",
       "funcao_nome                        0\n",
       "categoria_nome                     0\n",
       "situacao_nome                      0\n",
       "jornada_mensal                     0\n",
       "data_atualizacao_sistema           0\n",
       "ano_folha                          0\n",
       "mes_folha                          0\n",
       "valor_remuneracao_bruta            0\n",
       "valor_remuneracao_base             0\n",
       "valor_salario_base                 0\n",
       "valor_funcao_gratificada           0\n",
       "valor_outras_remuneracoes          0\n",
       "valor_ferias                       0\n",
       "valor_13_salario                   0\n",
       "valor_diferenca_salarial           0\n",
       "valor_irrf                         0\n",
       "valor_previdencia                  0\n",
       "valor_descontos_total              0\n",
       "valor_desconto_faltas              0\n",
       "valor_descontos_diversos           0\n",
       "valor_liquido                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:45.116419Z",
     "start_time": "2025-12-01T16:20:37.901350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['genero'] = df['genero'].fillna('NI')\n",
    "df['grau_instrucao'] = df['grau_instrucao'].fillna('NAO INFORMADO')\n",
    "df['unidade_nome'] = df['unidade_nome'].fillna('NAO INFORMADO')\n",
    "\n",
    "cols_texto = ['nome', 'lotacao_nome', 'unidade_nome', 'entidade_nome',\n",
    "              'cargo_nome', 'funcao_nome', 'categoria_nome', 'situacao_nome']\n",
    "\n",
    "for col in cols_texto:\n",
    "    df[col] = df[col].astype(str).str.strip().str.upper()\n",
    "    df[col] = df[col].str.replace(r'\\.+$', '', regex=True)\n",
    "    df[col] = df[col].replace({'NAN': np.nan, 'NONE': np.nan, '': np.nan})\n",
    "\n",
    "df.isnull().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matricula                          0\n",
       "cpf                                0\n",
       "nome                               0\n",
       "genero                             0\n",
       "grau_instrucao                     0\n",
       "data_admissao                     36\n",
       "data_desligamento            1113112\n",
       "data_aposentadoria           1053502\n",
       "lotacao_nome                       0\n",
       "unidade_nome                       0\n",
       "entidade_nome                      0\n",
       "tipo_administracao                 0\n",
       "cargo_nome                         0\n",
       "funcao_nome                        0\n",
       "categoria_nome                     0\n",
       "situacao_nome                      0\n",
       "jornada_mensal                     0\n",
       "data_atualizacao_sistema           0\n",
       "ano_folha                          0\n",
       "mes_folha                          0\n",
       "valor_remuneracao_bruta            0\n",
       "valor_remuneracao_base             0\n",
       "valor_salario_base                 0\n",
       "valor_funcao_gratificada           0\n",
       "valor_outras_remuneracoes          0\n",
       "valor_ferias                       0\n",
       "valor_13_salario                   0\n",
       "valor_diferenca_salarial           0\n",
       "valor_irrf                         0\n",
       "valor_previdencia                  0\n",
       "valor_descontos_total              0\n",
       "valor_desconto_faltas              0\n",
       "valor_descontos_diversos           0\n",
       "valor_liquido                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ao verificarmos os nulos remanescentes, notamos dois cenários distintos:\n",
    "1. Erro de Cadastro: A coluna 'data_admissao' possui 36 registros vazios.\n",
    "   Como esta data é fundamental para o cálculo de tempo de serviço, não podemos deixá-la vazia.\n",
    "   Adotaremos a data padrão '1900-01-01' (padrão de sistemas legados) para indicar \"Data Desconhecida\",\n",
    "   mantendo a consistência com a regra definida no modelo SQL (stg_servidores_unificados).\n",
    "\n",
    "2. Regra de Negócio: As colunas 'data_desligamento' e 'data_aposentadoria' possuem alto volume de nulos.\n",
    "   Isso é esperado e correto, pois indica que o servidor está ATIVO na folha.\n",
    "   Manteremos como NaT (Not a Time) para que o banco de dados entenda como NULL."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:45.570872Z",
     "start_time": "2025-12-01T16:20:45.419871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_padrao = pd.to_datetime('1900-01-01').date()\n",
    "df['data_admissao'] = df['data_admissao'].fillna(data_padrao)\n",
    "\n",
    "nulos_finais = df[['data_admissao', 'data_desligamento', 'data_aposentadoria']].isnull().sum()\n",
    "print(\"Status final dos nulos de data:\")\n",
    "print(nulos_finais)\n",
    "\n",
    "# Explicando o resultado para quem lê o notebook:\n",
    "print(\"\\nConclusão:\")\n",
    "print(f\"- Admissão: {nulos_finais['data_admissao']} nulos (Corrigido).\")\n",
    "print(f\"- Desligamento: {nulos_finais['data_desligamento']} nulos (Representam servidores ATIVOS).\")\n",
    "print(f\"- Aposentadoria: {nulos_finais['data_aposentadoria']} nulos (Representam servidores ATIVOS).\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status final dos nulos de data:\n",
      "data_admissao               0\n",
      "data_desligamento     1113112\n",
      "data_aposentadoria    1053502\n",
      "dtype: int64\n",
      "\n",
      "Conclusão:\n",
      "- Admissão: 0 nulos (Corrigido).\n",
      "- Desligamento: 1113112 nulos (Representam servidores ATIVOS).\n",
      "- Aposentadoria: 1053502 nulos (Representam servidores ATIVOS).\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RESULTADO FINAL"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:45.999183Z",
     "start_time": "2025-12-01T16:20:45.573798Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1398332 entries, 0 to 1398331\n",
      "Data columns (total 34 columns):\n",
      " #   Column                     Non-Null Count    Dtype  \n",
      "---  ------                     --------------    -----  \n",
      " 0   matricula                  1398332 non-null  object \n",
      " 1   cpf                        1398332 non-null  object \n",
      " 2   nome                       1398332 non-null  object \n",
      " 3   genero                     1398332 non-null  object \n",
      " 4   grau_instrucao             1398332 non-null  object \n",
      " 5   data_admissao              1398332 non-null  object \n",
      " 6   data_desligamento          285220 non-null   object \n",
      " 7   data_aposentadoria         344830 non-null   object \n",
      " 8   lotacao_nome               1398332 non-null  object \n",
      " 9   unidade_nome               1398332 non-null  object \n",
      " 10  entidade_nome              1398332 non-null  object \n",
      " 11  tipo_administracao         1398332 non-null  object \n",
      " 12  cargo_nome                 1398332 non-null  object \n",
      " 13  funcao_nome                1398332 non-null  object \n",
      " 14  categoria_nome             1398332 non-null  object \n",
      " 15  situacao_nome              1398332 non-null  object \n",
      " 16  jornada_mensal             1398332 non-null  float64\n",
      " 17  data_atualizacao_sistema   1398332 non-null  object \n",
      " 18  ano_folha                  1398332 non-null  int64  \n",
      " 19  mes_folha                  1398332 non-null  int64  \n",
      " 20  valor_remuneracao_bruta    1398332 non-null  float64\n",
      " 21  valor_remuneracao_base     1398332 non-null  float64\n",
      " 22  valor_salario_base         1398332 non-null  float64\n",
      " 23  valor_funcao_gratificada   1398332 non-null  float64\n",
      " 24  valor_outras_remuneracoes  1398332 non-null  float64\n",
      " 25  valor_ferias               1398332 non-null  float64\n",
      " 26  valor_13_salario           1398332 non-null  float64\n",
      " 27  valor_diferenca_salarial   1398332 non-null  float64\n",
      " 28  valor_irrf                 1398332 non-null  float64\n",
      " 29  valor_previdencia          1398332 non-null  float64\n",
      " 30  valor_descontos_total      1398332 non-null  float64\n",
      " 31  valor_desconto_faltas      1398332 non-null  float64\n",
      " 32  valor_descontos_diversos   1398332 non-null  float64\n",
      " 33  valor_liquido              1398332 non-null  float64\n",
      "dtypes: float64(15), int64(2), object(17)\n",
      "memory usage: 362.7+ MB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Com os dados limpos e tipados, avançamos para a modelagem dimensional. O objetivo aqui é sair de um tabela única para um Esquema Estrela, que otimiza o desempenho analítico e garante a integridade dos dados.\n",
    "\n",
    "As principais decisões de modelagem foram:\n",
    "\n",
    "- Normalização: Removemos a redundância de textos repetitivos (cargos, lotações, situações) movendo-os para tabelas de Dimensão.\n",
    "\n",
    "- Deduplicação de Servidores: Um servidor pode aparecer múltiplas vezes na base original (uma vez por mês/ano). Na `dim_servidor`, garantimos um registro único por matrícula, consolidando sua data de admissão mais antiga.\n",
    "\n",
    "- Chaves Substitutas: Criamos IDs numéricos (`id_cargo`, `id_servidor`) para isolar nossa estrutura interna de mudanças nos sistemas de origem."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:46.030818Z",
     "start_time": "2025-12-01T16:20:46.002074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dim_tempo = df[['ano_folha', 'mes_folha']].drop_duplicates().sort_values(['ano_folha', 'mes_folha']).reset_index(drop=True)\n",
    "\n",
    "dim_tempo['id_tempo'] = dim_tempo['ano_folha'] * 100 + dim_tempo['mes_folha']\n",
    "\n",
    "dim_tempo['semestre'] = dim_tempo['mes_folha'].apply(lambda x: 1 if x <= 6 else 2)\n",
    "dim_tempo['trimestre'] = dim_tempo['mes_folha'].apply(lambda x: (x - 1) // 3 + 1)\n",
    "\n",
    "mapa_meses = {\n",
    "    1:'JANEIRO', 2:'FEVEREIRO', 3:'MARCO', 4:'ABRIL', 5:'MAIO', 6:'JUNHO',\n",
    "    7:'JULHO', 8:'AGOSTO', 9:'SETEMBRO', 10:'OUTUBRO', 11:'NOVEMBRO', 12:'DEZEMBRO'\n",
    "}\n",
    "dim_tempo['nome_mes'] = dim_tempo['mes_folha'].map(mapa_meses)\n",
    "\n",
    "print(f\"Dimensão Tempo criada: {len(dim_tempo)} registros.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão Tempo criada: 36 registros.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:46.240913Z",
     "start_time": "2025-12-01T16:20:46.048591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_cargo = ['cargo_nome', 'funcao_nome', 'categoria_nome']\n",
    "dim_cargo = df[cols_cargo].drop_duplicates().sort_values(cols_cargo).reset_index(drop=True)\n",
    "dim_cargo['id_cargo'] = dim_cargo.index + 1\n",
    "\n",
    "print(f\"Dimensão Cargo criada: {len(dim_cargo)} registros.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão Cargo criada: 1869 registros.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:46.315612Z",
     "start_time": "2025-12-01T16:20:46.250394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dim_situacao = df[['situacao_nome']].drop_duplicates().sort_values('situacao_nome').reset_index(drop=True)\n",
    "dim_situacao['id_situacao'] = dim_situacao.index + 1\n",
    "dim_situacao['is_ativo'] = ~dim_situacao['situacao_nome'].str.contains('DESLIGADO/EXONERADO|APOSENTADO', na=False, case=False)\n",
    "\n",
    "print(f\"Dimensão Situação criada: {len(dim_situacao)} registros.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão Situação criada: 3 registros.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:46.754889Z",
     "start_time": "2025-12-01T16:20:46.326106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_lotacao = ['lotacao_nome', 'unidade_nome', 'entidade_nome', 'tipo_administracao']\n",
    "\n",
    "dim_lotacao = df[cols_lotacao].drop_duplicates()\n",
    "dim_lotacao = dim_lotacao.sort_values(['entidade_nome', 'unidade_nome', 'lotacao_nome']).reset_index(drop=True)\n",
    "dim_lotacao['id_lotacao'] = dim_lotacao.index + 1\n",
    "\n",
    "print(f\"Dimensão Lotação criada: {len(dim_lotacao)} registros.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão Lotação criada: 3024 registros.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:49.870317Z",
     "start_time": "2025-12-01T16:20:46.778143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_datas = ['data_admissao', 'data_desligamento', 'data_aposentadoria']\n",
    "for col in cols_datas:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "cols_chave_servidor = ['matricula', 'entidade_nome', 'cpf']\n",
    "\n",
    "dim_servidor = df.groupby(cols_chave_servidor).agg({\n",
    "    'nome': 'max',\n",
    "    'genero': 'max',\n",
    "    'grau_instrucao': 'max',\n",
    "    'data_admissao': 'min',\n",
    "    'data_desligamento': 'max',\n",
    "    'data_aposentadoria': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "for col in cols_datas:\n",
    "    dim_servidor[col] = dim_servidor[col].dt.date\n",
    "\n",
    "dim_servidor['id_servidor'] = dim_servidor.index + 1\n",
    "\n",
    "print(f\"Dimensão Servidor criada: {len(dim_servidor)} registros únicos.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão Servidor criada: 49966 registros únicos.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Realizamos o cruzamento do dataset principal com as dimensões criadas anteriormente. O objetivo é substituir os textos descritivos pelos IDs numéricos (Foreign Keys) e manter na tabela de fatos apenas as colunas de métricas financeiras e horas trabalhadas."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:52.549835Z",
     "start_time": "2025-12-01T16:20:49.917279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fato_folha = df.copy()\n",
    "\n",
    "fato_folha['id_tempo'] = fato_folha['ano_folha'] * 100 + fato_folha['mes_folha']\n",
    "\n",
    "fato_folha = pd.merge(fato_folha, dim_cargo, on=['cargo_nome', 'funcao_nome', 'categoria_nome'], how='left')\n",
    "fato_folha = pd.merge(fato_folha, dim_situacao, on='situacao_nome', how='left')\n",
    "fato_folha = pd.merge(fato_folha, dim_lotacao, on=['lotacao_nome', 'unidade_nome', 'entidade_nome', 'tipo_administracao'], how='left')\n",
    "fato_folha = pd.merge(fato_folha, dim_servidor[['matricula', 'entidade_nome', 'cpf', 'id_servidor']],\n",
    "                      on=['matricula', 'entidade_nome', 'cpf'], how='left')\n",
    "\n",
    "cols_finais = [\n",
    "    'id_servidor', 'id_cargo', 'id_lotacao', 'id_tempo', 'id_situacao',\n",
    "    'jornada_mensal',\n",
    "    'valor_salario_base', 'valor_remuneracao_bruta', 'valor_liquido',\n",
    "    'valor_previdencia', 'valor_irrf', 'valor_descontos_total',\n",
    "    'valor_ferias', 'valor_13_salario'\n",
    "]\n",
    "\n",
    "fato_folha_final = fato_folha[cols_finais]\n",
    "\n",
    "print(f\"Fato Folha montada: {fato_folha_final.shape}\")\n",
    "display(fato_folha_final.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fato Folha montada: (1398332, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   id_servidor  id_cargo  id_lotacao  id_tempo  id_situacao  jornada_mensal  \\\n",
       "0        25471      1866         297    201904            3           220.0   \n",
       "1        25576      1866         297    201904            3           220.0   \n",
       "2        26617      1007         283    201904            3           110.0   \n",
       "3        26618      1007         179    201904            3           110.0   \n",
       "4        26619      1007         283    201904            3           110.0   \n",
       "\n",
       "   valor_salario_base  valor_remuneracao_bruta  valor_liquido  \\\n",
       "0              1198.8                   1643.4         1512.0   \n",
       "1              1198.8                   2147.8         1911.9   \n",
       "2                 0.0                    377.0          377.0   \n",
       "3                 0.0                    377.0          377.0   \n",
       "4                 0.0                    377.0          377.0   \n",
       "\n",
       "   valor_previdencia  valor_irrf  valor_descontos_total  valor_ferias  \\\n",
       "0              131.5         0.0                  131.5           0.0   \n",
       "1              183.9         0.0                  235.9           0.0   \n",
       "2                0.0         0.0                    0.0           0.0   \n",
       "3                0.0         0.0                    0.0           0.0   \n",
       "4                0.0         0.0                    0.0           0.0   \n",
       "\n",
       "   valor_13_salario  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_servidor</th>\n",
       "      <th>id_cargo</th>\n",
       "      <th>id_lotacao</th>\n",
       "      <th>id_tempo</th>\n",
       "      <th>id_situacao</th>\n",
       "      <th>jornada_mensal</th>\n",
       "      <th>valor_salario_base</th>\n",
       "      <th>valor_remuneracao_bruta</th>\n",
       "      <th>valor_liquido</th>\n",
       "      <th>valor_previdencia</th>\n",
       "      <th>valor_irrf</th>\n",
       "      <th>valor_descontos_total</th>\n",
       "      <th>valor_ferias</th>\n",
       "      <th>valor_13_salario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25471</td>\n",
       "      <td>1866</td>\n",
       "      <td>297</td>\n",
       "      <td>201904</td>\n",
       "      <td>3</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1198.8</td>\n",
       "      <td>1643.4</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>131.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25576</td>\n",
       "      <td>1866</td>\n",
       "      <td>297</td>\n",
       "      <td>201904</td>\n",
       "      <td>3</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1198.8</td>\n",
       "      <td>2147.8</td>\n",
       "      <td>1911.9</td>\n",
       "      <td>183.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26617</td>\n",
       "      <td>1007</td>\n",
       "      <td>283</td>\n",
       "      <td>201904</td>\n",
       "      <td>3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26618</td>\n",
       "      <td>1007</td>\n",
       "      <td>179</td>\n",
       "      <td>201904</td>\n",
       "      <td>3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26619</td>\n",
       "      <td>1007</td>\n",
       "      <td>283</td>\n",
       "      <td>201904</td>\n",
       "      <td>3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carga no Data Warehouse"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Por fim, enviamos as tabelas modeladas (`dim_` e `fato_`) para o banco de dados PostgreSQL, utilizando SQLALchemy. As variáveis de ambiente são definidas no arquivo `.env`."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:20:52.672449Z",
     "start_time": "2025-12-01T16:20:52.612537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "db_user = os.getenv('POSTGRES_USER')\n",
    "db_password = os.getenv('POSTGRES_PASSWORD')\n",
    "db_host = os.getenv('POSTGRES_HOST')\n",
    "db_port = os.getenv('POSTGRES_PORT')\n",
    "db_name = os.getenv('POSTGRES_DB')\n",
    "\n",
    "DATABASE_URL = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "print(\"Engine de banco de dados criada.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine de banco de dados criada.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T16:21:40.420131Z",
     "start_time": "2025-12-01T16:20:52.679130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def carregar_tabela(df, nome_tabela, engine, schema='public'):\n",
    "    print(f\"Carregando tabela {nome_tabela}...\")\n",
    "    df.to_sql(nome_tabela, con=engine, if_exists='replace', index=False, schema=schema)\n",
    "    print(f\"Tabela {nome_tabela} carregada com sucesso!\")\n",
    "\n",
    "schema_destino = 'servidores_etl'\n",
    "\n",
    "with engine.begin() as connection:\n",
    "    connection.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {schema_destino};\"))\n",
    "\n",
    "carregar_tabela(dim_tempo, 'dim_tempo', engine, schema_destino)\n",
    "carregar_tabela(dim_cargo, 'dim_cargo', engine, schema_destino)\n",
    "carregar_tabela(dim_situacao, 'dim_situacao', engine, schema_destino)\n",
    "carregar_tabela(dim_lotacao, 'dim_lotacao', engine, schema_destino)\n",
    "carregar_tabela(dim_servidor, 'dim_servidor', engine, schema_destino)\n",
    "carregar_tabela(fato_folha_final, 'fato_folha', engine, schema_destino)\n",
    "\n",
    "print(\"ETL concluído com sucesso!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando tabela dim_tempo...\n",
      "Tabela dim_tempo carregada com sucesso!\n",
      "Carregando tabela dim_cargo...\n",
      "Tabela dim_cargo carregada com sucesso!\n",
      "Carregando tabela dim_situacao...\n",
      "Tabela dim_situacao carregada com sucesso!\n",
      "Carregando tabela dim_lotacao...\n",
      "Tabela dim_lotacao carregada com sucesso!\n",
      "Carregando tabela dim_servidor...\n",
      "Tabela dim_servidor carregada com sucesso!\n",
      "Carregando tabela fato_folha...\n",
      "Tabela fato_folha carregada com sucesso!\n",
      "ETL concluído com sucesso!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Resumo\n",
    "Neste notebook, implementamos um pipeline de dados completo, reproduzindo a lógica de engenharia de dados moderna (ETL) utilizando Python e Pandas. As etapas percorridas foram:\n",
    "1. **Extract (Extração):**\n",
    "\n",
    "      * Ingestão de dados brutos de múltiplos anos (CSV).\n",
    "      * Tratamento de arquivos com formatação inconsistente de aspas (`csv.QUOTE_NONE`), uma característica comum em dumps de sistemas legados.\n",
    "\n",
    "2. **Transform (Transformação):**\n",
    "\n",
    "      * Padronização de nomes de colunas, tipagem (conversão de strings para inteiros/datas) e tratamento de nulos (`NAO INFORMADO`, datas padrão `1900-01-01`).\n",
    "      * Criação de um Esquema Estrela, separando entidades (Servidor, Cargo, Lotação) de eventos (Pagamentos na Fato), facilitando análises futuras.\n",
    "\n",
    "3. **Load (Carga):**\n",
    "\n",
    "      * Carga dos dados modelados em um banco de dados (PostgreSQL - Schema `servidores_etl`), prontos para consumo por ferramentas de BI ou comparação de qualidade com o pipeline ELT (dbt)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
